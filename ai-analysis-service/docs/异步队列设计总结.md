# AI分析服务 - 异步队列设计总结

## 📌 核心设计理念

AI分析服务的异步队列系统采用 **Worker Pool + FIFO Queue** 模式，基于Python的`asyncio`实现，旨在：
- ✅ 控制并发，避免资源耗尽
- ✅ 提供任务追踪和管理能力
- ✅ 支持失败重试和错误恢复
- ✅ 实现异步非阻塞处理

## 🏗️ 架构概览

```
┌─────────────────────────────────────────────────────────────┐
│                      客户端层                                │
│         小程序 → 云函数 → AI分析服务                         │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                   FastAPI应用层                              │
│  POST /analyze      │ GET /task/:id  │ DELETE /task/:id    │
│  POST /analyze/sync │ GET /queue/stats                      │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                RequestQueue（队列管理器）                     │
│  ┌──────────────┐  ┌──────────────┐  ┌──────────────┐      │
│  │ asyncio.Queue│  │ tasks: Dict  │  │ Worker Pool  │      │
│  │ (FIFO队列)   │  │ (任务存储)   │  │ (3个协程)    │      │
│  └──────────────┘  └──────────────┘  └──────────────┘      │
└─────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────┐
│                  AIAnalysisService                           │
│         PDF解析 → Dify AI分析 → 结果生成                    │
└─────────────────────────────────────────────────────────────┘
```

## 🔑 核心组件

### 1. RequestQueue（队列管理器）
**文件位置**：`ai-analysis-service/app/utils/queue_manager.py`

**核心属性**：
```python
max_concurrent_tasks: int = 3      # 最大并发任务数
max_queue_size: int = 100          # 最大队列长度
queue: asyncio.Queue               # 异步FIFO队列
tasks: Dict[str, QueueTask]        # 任务存储（内存）
processing_tasks: Dict             # 处理中的协程任务
worker_tasks: List                 # Worker协程池
```

**核心方法**：
- `start()` - 启动队列，创建Worker协程池
- `stop()` - 停止队列，取消所有任务
- `add_task()` - 添加任务到队列
- `get_task_status()` - 查询任务状态
- `cancel_task()` - 取消任务
- `_worker()` - Worker协程（从队列获取并处理任务）
- `_process_task()` - 处理单个任务

### 2. QueueTask（任务数据结构）
```python
@dataclass
class QueueTask:
    task_id: str                    # UUID唯一标识
    request_data: Dict              # 请求数据
    status: TaskStatus              # 任务状态
    created_at: float               # 创建时间戳
    started_at: Optional[float]     # 开始时间戳
    completed_at: Optional[float]   # 完成时间戳
    result: Optional[Dict]          # 处理结果
    error_message: Optional[str]    # 错误信息
    retry_count: int = 0            # 重试次数
    max_retries: int = 2            # 最大重试次数
```

### 3. TaskStatus（任务状态）
```python
class TaskStatus(str, Enum):
    PENDING = "pending"        # 等待处理
    PROCESSING = "processing"  # 正在处理
    COMPLETED = "completed"    # 处理完成
    FAILED = "failed"         # 处理失败
    CANCELLED = "cancelled"   # 已取消
```

## 🔄 工作流程

### 完整流程图
```
1. 任务提交
   客户端 → POST /analyze → 生成task_id → 入队 → 返回task_id

2. Worker处理
   Worker循环 → queue.get() → 更新状态=PROCESSING 
   → 调用AIAnalysisService → 等待结果 
   → 更新状态=COMPLETED/FAILED → queue.task_done()

3. 失败重试
   处理失败 → retry_count < 2 → 重新入队 → 再次处理
   处理失败 → retry_count >= 2 → 标记FAILED → 结束

4. 状态查询
   客户端 → GET /task/:id → 返回任务状态和结果

5. 任务取消
   客户端 → DELETE /task/:id → 取消协程 → 标记CANCELLED
```

### 状态转换
```
PENDING → PROCESSING → COMPLETED ✅
        ↓             ↓
    CANCELLED      FAILED → PENDING (重试) → ...
                      ↓
                   FAILED (最终失败) ❌
```

## 📡 API接口设计

### 1. 提交任务（异步）
```http
POST /analyze
{
  "file_base64": "...",
  "mime_type": "application/pdf",
  "report_type": "flow"
}

响应：
{
  "success": true,
  "task_id": "uuid",
  "estimated_wait_time": 60,
  "queue_position": 2
}
```

### 2. 查询任务状态
```http
GET /task/{task_id}

响应：
{
  "task_id": "uuid",
  "status": "completed",
  "processing_time": 20.0,
  "wait_time": 10.0,
  "result": { ... }
}
```

### 3. 取消任务
```http
DELETE /task/{task_id}
```

### 4. 队列统计
```http
GET /queue/stats

响应：
{
  "total_requests": 1250,
  "completed_requests": 1180,
  "failed_requests": 45,
  "current_queue_size": 3,
  "current_processing": 2
}
```

### 5. 同步处理（不使用队列）
```http
POST /analyze/sync
```
用于紧急或小文件的即时处理，直接调用AI服务。

## 🔌 云函数集成

### processReportAsync（提交任务）
**文件位置**：`cloudFunctions/processReportAsync/index.js`

**流程**：
1. 下载用户上传的文件
2. 调用 `POST /analyze/sync` 同步分析（当前实现）
3. 保存结果到数据库

**注意**：当前使用 `/analyze/sync` 同步接口，未来可改为 `/analyze` 异步接口。

### checkTaskStatus（查询状态）
**文件位置**：`cloudFunctions/checkTaskStatus/index.js`

**流程**：
1. 调用 `GET /task/{taskId}` 查询状态
2. 根据状态更新数据库
3. 如果完成，生成报告文件并上传到云存储
4. 如果失败，清理记录

## ⚙️ 配置参数

| 参数 | 默认值 | 说明 |
|------|--------|------|
| `max_concurrent_tasks` | 3 | 最大并发任务数（Worker数量） |
| `max_queue_size` | 100 | 最大队列长度 |
| `max_retries` | 2 | 最大重试次数 |
| `worker_timeout` | 1.0秒 | Worker获取任务超时时间 |

## 📊 性能指标

| 指标 | 当前值 | 说明 |
|------|--------|------|
| 最大并发 | 3个任务 | 同时处理的任务数 |
| 队列容量 | 100个任务 | 等待队列的最大长度 |
| 平均处理时间 | 20-30秒 | 单个任务的平均耗时 |
| 吞吐量 | 6-9个/分钟 | 每分钟处理的任务数 |
| 重试次数 | 最多2次 | 失败后的重试次数 |

## 🎯 设计优势

### ✅ 优点
1. **并发控制**：通过Worker Pool限制并发，避免资源耗尽
2. **异步非阻塞**：基于asyncio，高效利用I/O等待时间
3. **任务追踪**：每个任务有唯一ID，可随时查询状态
4. **失败重试**：自动重试失败任务，提高成功率
5. **优雅关闭**：支持平滑停止，不丢失任务
6. **实时监控**：提供队列统计和健康检查接口

### ⚠️ 局限性
1. **内存存储**：任务存储在内存中，服务重启会丢失
2. **单机部署**：无法跨服务器共享队列
3. **无优先级**：FIFO策略，无法优先处理VIP用户
4. **无持久化**：未完成的任务在重启后丢失

## 🚀 优化建议

### 短期优化
1. **增加并发数**：从3提升到5-10（需要更多资源）
2. **任务持久化**：使用SQLite/Redis存储任务状态
3. **结果缓存**：相同文件直接返回缓存结果

### 长期优化
1. **分布式队列**：使用Redis/RabbitMQ/Celery
2. **任务优先级**：VIP用户优先处理
3. **水平扩展**：多服务器共享队列
4. **监控告警**：集成Prometheus/Grafana

## 📁 相关文件

| 文件 | 说明 |
|------|------|
| `ai-analysis-service/app/utils/queue_manager.py` | 队列管理器核心实现 |
| `ai-analysis-service/app/main.py` | FastAPI路由和启动逻辑 |
| `ai-analysis-service/app/models/report_model.py` | 数据模型定义 |
| `ai-analysis-service/app/service/ai_service.py` | AI分析服务 |
| `cloudFunctions/processReportAsync/index.js` | 云函数：提交任务 |
| `cloudFunctions/checkTaskStatus/index.js` | 云函数：查询状态 |

---

**文档版本**：v1.0  
**最后更新**：2025-11-26  
**维护者**：AI分析服务团队
