# AIåˆ†ææœåŠ¡ - å¼‚æ­¥é˜Ÿåˆ—è®¾è®¡æ–‡æ¡£

## ğŸ“‹ ç›®å½•
- [è®¾è®¡æ¦‚è¿°](#è®¾è®¡æ¦‚è¿°)
- [æ ¸å¿ƒç»„ä»¶](#æ ¸å¿ƒç»„ä»¶)
- [å·¥ä½œæµç¨‹](#å·¥ä½œæµç¨‹)
- [APIæ¥å£](#apiæ¥å£)
- [é…ç½®å‚æ•°](#é…ç½®å‚æ•°)
- [ç›‘æ§ç»Ÿè®¡](#ç›‘æ§ç»Ÿè®¡)
- [é”™è¯¯å¤„ç†](#é”™è¯¯å¤„ç†)

## ğŸ¯ è®¾è®¡æ¦‚è¿°

### è®¾è®¡ç›®æ ‡
å¼‚æ­¥é˜Ÿåˆ—ç³»ç»Ÿæ—¨åœ¨è§£å†³ä»¥ä¸‹é—®é¢˜ï¼š
1. **å¹¶å‘æ§åˆ¶**ï¼šé™åˆ¶åŒæ—¶å¤„ç†çš„AIåˆ†æä»»åŠ¡æ•°é‡ï¼Œé¿å…èµ„æºè€—å°½
2. **è¯·æ±‚æ’é˜Ÿ**ï¼šå½“å¹¶å‘è¾¾åˆ°ä¸Šé™æ—¶ï¼Œæ–°è¯·æ±‚è¿›å…¥é˜Ÿåˆ—ç­‰å¾…
3. **ä»»åŠ¡è¿½è¸ª**ï¼šæä¾›ä»»åŠ¡çŠ¶æ€æŸ¥è¯¢ã€å–æ¶ˆç­‰ç®¡ç†åŠŸèƒ½
4. **å¤±è´¥é‡è¯•**ï¼šè‡ªåŠ¨é‡è¯•å¤±è´¥çš„ä»»åŠ¡ï¼ˆæœ€å¤š2æ¬¡ï¼‰
5. **æ€§èƒ½ç›‘æ§**ï¼šå®æ—¶ç»Ÿè®¡é˜Ÿåˆ—çŠ¶æ€å’Œå¤„ç†æ€§èƒ½

### æŠ€æœ¯é€‰å‹
- **é˜Ÿåˆ—å®ç°**ï¼š`asyncio.Queue` - PythonåŸç”Ÿå¼‚æ­¥é˜Ÿåˆ—
- **å¹¶å‘æ¨¡å‹**ï¼šWorker Poolæ¨¡å¼ - å›ºå®šæ•°é‡çš„å·¥ä½œåç¨‹
- **çŠ¶æ€ç®¡ç†**ï¼šå†…å­˜å­—å…¸å­˜å‚¨ï¼ˆ`Dict[str, QueueTask]`ï¼‰
- **ä»»åŠ¡è°ƒåº¦**ï¼šFIFOï¼ˆå…ˆè¿›å…ˆå‡ºï¼‰ç­–ç•¥

## ğŸ”§ æ ¸å¿ƒç»„ä»¶

### 1. TaskStatusï¼ˆä»»åŠ¡çŠ¶æ€æšä¸¾ï¼‰
```python
class TaskStatus(str, Enum):
    PENDING = "pending"        # ç­‰å¾…å¤„ç†
    PROCESSING = "processing"  # æ­£åœ¨å¤„ç†
    COMPLETED = "completed"    # å¤„ç†å®Œæˆ
    FAILED = "failed"         # å¤„ç†å¤±è´¥
    CANCELLED = "cancelled"   # å·²å–æ¶ˆ
```

### 2. QueueTaskï¼ˆé˜Ÿåˆ—ä»»åŠ¡ï¼‰
```python
@dataclass
class QueueTask:
    task_id: str                           # ä»»åŠ¡å”¯ä¸€æ ‡è¯†ï¼ˆUUIDï¼‰
    request_data: Dict[str, Any]           # è¯·æ±‚æ•°æ®
    status: TaskStatus                     # ä»»åŠ¡çŠ¶æ€
    created_at: float                      # åˆ›å»ºæ—¶é—´æˆ³
    started_at: Optional[float]            # å¼€å§‹å¤„ç†æ—¶é—´æˆ³
    completed_at: Optional[float]          # å®Œæˆæ—¶é—´æˆ³
    result: Optional[Dict[str, Any]]       # å¤„ç†ç»“æœ
    error_message: Optional[str]           # é”™è¯¯ä¿¡æ¯
    retry_count: int = 0                   # é‡è¯•æ¬¡æ•°
    max_retries: int = 2                   # æœ€å¤§é‡è¯•æ¬¡æ•°
```

**è®¡ç®—å±æ€§**ï¼š
- `processing_time`: å¤„ç†è€—æ—¶ï¼ˆç§’ï¼‰
- `wait_time`: ç­‰å¾…è€—æ—¶ï¼ˆç§’ï¼‰

### 3. RequestQueueï¼ˆè¯·æ±‚é˜Ÿåˆ—ç®¡ç†å™¨ï¼‰

#### æ ¸å¿ƒå±æ€§
```python
max_concurrent_tasks: int = 3      # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
max_queue_size: int = 100          # æœ€å¤§é˜Ÿåˆ—é•¿åº¦
queue: asyncio.Queue               # å¼‚æ­¥é˜Ÿåˆ—
tasks: Dict[str, QueueTask]        # ä»»åŠ¡å­˜å‚¨ï¼ˆtask_id -> QueueTaskï¼‰
processing_tasks: Dict[str, Task]  # å¤„ç†ä¸­çš„åç¨‹ä»»åŠ¡
worker_tasks: List[Task]           # å·¥ä½œåç¨‹åˆ—è¡¨
is_running: bool                   # é˜Ÿåˆ—è¿è¡ŒçŠ¶æ€
```

#### æ ¸å¿ƒæ–¹æ³•

**å¯åŠ¨ä¸åœæ­¢**
- `async start()`: å¯åŠ¨é˜Ÿåˆ—ï¼Œåˆ›å»ºå·¥ä½œåç¨‹æ± 
- `async stop()`: åœæ­¢é˜Ÿåˆ—ï¼Œå–æ¶ˆæ‰€æœ‰ä»»åŠ¡

**ä»»åŠ¡ç®¡ç†**
- `async add_task(request_data)`: æ·»åŠ ä»»åŠ¡åˆ°é˜Ÿåˆ—ï¼Œè¿”å›task_id
- `async get_task_status(task_id)`: æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
- `async cancel_task(task_id)`: å–æ¶ˆä»»åŠ¡
- `get_queue_stats()`: è·å–é˜Ÿåˆ—ç»Ÿè®¡ä¿¡æ¯

**å†…éƒ¨æ–¹æ³•**
- `async _worker(worker_name)`: å·¥ä½œåç¨‹ï¼Œä»é˜Ÿåˆ—è·å–å¹¶å¤„ç†ä»»åŠ¡
- `async _process_task(task, worker_name)`: å¤„ç†å•ä¸ªä»»åŠ¡

## ğŸ”„ å·¥ä½œæµç¨‹

### 1. ç³»ç»Ÿå¯åŠ¨æµç¨‹
```
FastAPIå¯åŠ¨ 
  â†’ startup_event() 
  â†’ request_queue.start() 
  â†’ åˆ›å»º3ä¸ªWorkeråç¨‹
  â†’ æ¯ä¸ªWorkerè¿›å…¥å¾ªç¯ç­‰å¾…ä»»åŠ¡
```

### 2. ä»»åŠ¡æäº¤æµç¨‹
```
å®¢æˆ·ç«¯è¯·æ±‚ 
  â†’ POST /analyze 
  â†’ éªŒè¯è¯·æ±‚å‚æ•°
  â†’ ç”ŸæˆUUIDä½œä¸ºtask_id
  â†’ åˆ›å»ºQueueTaskå¯¹è±¡ï¼ˆstatus=PENDINGï¼‰
  â†’ æ”¾å…¥asyncio.Queue
  â†’ å­˜å‚¨åˆ°taskså­—å…¸
  â†’ è¿”å›task_idç»™å®¢æˆ·ç«¯
```

### 3. ä»»åŠ¡å¤„ç†æµç¨‹
```
Workeråç¨‹å¾ªç¯
  â†’ queue.get() è·å–ä»»åŠ¡ï¼ˆè¶…æ—¶1ç§’ï¼‰
  â†’ æ£€æŸ¥ä»»åŠ¡æ˜¯å¦å·²å–æ¶ˆ
  â†’ æ›´æ–°çŠ¶æ€ä¸ºPROCESSING
  â†’ è°ƒç”¨AIAnalysisService.analyze_document()
  â†’ ç­‰å¾…å¤„ç†å®Œæˆ
  â†’ æ›´æ–°ç»“æœå’ŒçŠ¶æ€ï¼ˆCOMPLETED/FAILEDï¼‰
  â†’ å¤±è´¥æ—¶åˆ¤æ–­æ˜¯å¦é‡è¯•
  â†’ queue.task_done()
```

### 4. é‡è¯•æœºåˆ¶
```
ä»»åŠ¡å¤±è´¥
  â†’ æ£€æŸ¥retry_count < max_retries (2)
  â†’ æ˜¯ï¼šretry_count++ï¼Œé‡ç½®çŠ¶æ€ä¸ºPENDINGï¼Œé‡æ–°å…¥é˜Ÿ
  â†’ å¦ï¼šæ ‡è®°ä¸ºFAILEDï¼Œè®°å½•é”™è¯¯ä¿¡æ¯
```

## ğŸ“¡ APIæ¥å£

### 1. æäº¤åˆ†æä»»åŠ¡ï¼ˆå¼‚æ­¥ï¼‰
```http
POST /analyze
Content-Type: application/json

{
  "file_base64": "JVBERi0xLjQK...",
  "mime_type": "application/pdf",
  "report_type": "flow",
  "custom_prompt": "å¯é€‰æç¤ºè¯"
}
```

**å“åº”**ï¼š
```json
{
  "success": true,
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "message": "ä»»åŠ¡å·²æˆåŠŸæäº¤åˆ°å¤„ç†é˜Ÿåˆ—",
  "estimated_wait_time": 60.0,
  "queue_position": 2
}
```

### 2. æŸ¥è¯¢ä»»åŠ¡çŠ¶æ€
```http
GET /task/{task_id}
```

**å“åº”**ï¼š
```json
{
  "task_id": "550e8400-e29b-41d4-a716-446655440000",
  "status": "completed",
  "created_at": 1703123456.789,
  "started_at": 1703123466.789,
  "completed_at": 1703123486.789,
  "processing_time": 20.0,
  "wait_time": 10.0,
  "result": { ... },
  "error_message": null,
  "retry_count": 0
}
```

### 3. å–æ¶ˆä»»åŠ¡
```http
DELETE /task/{task_id}
```

**å“åº”**ï¼š
```json
{
  "message": "ä»»åŠ¡å·²å–æ¶ˆ: 550e8400-e29b-41d4-a716-446655440000"
}
```

### 4. é˜Ÿåˆ—ç»Ÿè®¡
```http
GET /queue/stats
```

**å“åº”**ï¼š
```json
{
  "total_requests": 1250,
  "completed_requests": 1180,
  "failed_requests": 45,
  "current_queue_size": 3,
  "current_processing": 2,
  "queue_capacity": 100,
  "max_concurrent": 3,
  "is_running": true
}
```

### 5. åŒæ­¥åˆ†æï¼ˆä¸ä½¿ç”¨é˜Ÿåˆ—ï¼‰
```http
POST /analyze/sync
```
ç”¨äºç´§æ€¥æˆ–å°æ–‡ä»¶çš„å³æ—¶å¤„ç†ï¼Œç›´æ¥è°ƒç”¨AIæœåŠ¡ï¼Œä¸ç»è¿‡é˜Ÿåˆ—ã€‚

## âš™ï¸ é…ç½®å‚æ•°

### é˜Ÿåˆ—é…ç½®
```python
# åœ¨ queue_manager.py ä¸­
request_queue = RequestQueue(
    max_concurrent_tasks=3,   # æœ€å¤§å¹¶å‘ä»»åŠ¡æ•°
    max_queue_size=100        # æœ€å¤§é˜Ÿåˆ—é•¿åº¦
)
```

### é‡è¯•é…ç½®
```python
# åœ¨ QueueTask ä¸­
max_retries: int = 2          # æœ€å¤§é‡è¯•æ¬¡æ•°
```

### Workerè¶…æ—¶é…ç½®
```python
# åœ¨ _worker æ–¹æ³•ä¸­
task = await asyncio.wait_for(
    self.queue.get(),
    timeout=1.0               # è·å–ä»»åŠ¡è¶…æ—¶æ—¶é—´ï¼ˆç§’ï¼‰
)
```

## ğŸ“Š ç›‘æ§ç»Ÿè®¡

### å®æ—¶ç»Ÿè®¡æŒ‡æ ‡
é˜Ÿåˆ—ç®¡ç†å™¨ç»´æŠ¤ä»¥ä¸‹ç»Ÿè®¡ä¿¡æ¯ï¼š

| æŒ‡æ ‡ | è¯´æ˜ | ç”¨é€” |
|------|------|------|
| `total_requests` | æ€»è¯·æ±‚æ•° | ç´¯è®¡æ¥æ”¶çš„ä»»åŠ¡æ€»æ•° |
| `completed_requests` | å®Œæˆè¯·æ±‚æ•° | æˆåŠŸå®Œæˆçš„ä»»åŠ¡æ•° |
| `failed_requests` | å¤±è´¥è¯·æ±‚æ•° | æœ€ç»ˆå¤±è´¥çš„ä»»åŠ¡æ•° |
| `current_queue_size` | å½“å‰é˜Ÿåˆ—é•¿åº¦ | ç­‰å¾…å¤„ç†çš„ä»»åŠ¡æ•° |
| `current_processing` | å½“å‰å¤„ç†ä¸­ä»»åŠ¡æ•° | æ­£åœ¨æ‰§è¡Œçš„ä»»åŠ¡æ•° |
| `queue_capacity` | é˜Ÿåˆ—å®¹é‡ | æœ€å¤§é˜Ÿåˆ—é•¿åº¦ |
| `max_concurrent` | æœ€å¤§å¹¶å‘æ•° | Workeræ•°é‡ |
| `is_running` | è¿è¡ŒçŠ¶æ€ | é˜Ÿåˆ—æ˜¯å¦æ­£åœ¨è¿è¡Œ |

### å¥åº·æ£€æŸ¥
```http
GET /health
```

å“åº”ä¸­åŒ…å«é˜Ÿåˆ—çŠ¶æ€ï¼š
```json
{
  "status": "healthy",
  "services": {
    "request_queue": {
      "status": "running",
      "current_queue_size": 2,
      "current_processing": 1,
      "total_processed": 156
    }
  }
}
```

## âš ï¸ é”™è¯¯å¤„ç†

### 1. é˜Ÿåˆ—æ»¡é”™è¯¯
**åœºæ™¯**ï¼šé˜Ÿåˆ—é•¿åº¦è¾¾åˆ°max_queue_sizeï¼ˆ100ï¼‰

**å¤„ç†**ï¼š
```python
if self.queue.qsize() >= self.max_queue_size:
    raise RuntimeError(f"é˜Ÿåˆ—å·²æ»¡ï¼Œå½“å‰é•¿åº¦: {self.queue.qsize()}")
```

**å®¢æˆ·ç«¯å“åº”**ï¼šHTTP 500ï¼Œå»ºè®®ç¨åé‡è¯•

### 2. ä»»åŠ¡å¤„ç†å¤±è´¥
**åœºæ™¯**ï¼šAIåˆ†æè¿‡ç¨‹ä¸­å‡ºç°å¼‚å¸¸

**å¤„ç†**ï¼š
- ç¬¬1æ¬¡å¤±è´¥ï¼šè‡ªåŠ¨é‡è¯•ï¼ˆretry_count=1ï¼‰
- ç¬¬2æ¬¡å¤±è´¥ï¼šå†æ¬¡é‡è¯•ï¼ˆretry_count=2ï¼‰
- ç¬¬3æ¬¡å¤±è´¥ï¼šæ ‡è®°ä¸ºFAILEDï¼Œä¸å†é‡è¯•

**æ—¥å¿—è®°å½•**ï¼š
```python
logger.warning(f"ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œé‡è¯• {task.retry_count}/{task.max_retries}: {task_id}")
logger.error(f"ä»»åŠ¡å¤„ç†å¤±è´¥ï¼Œå·²è¾¾æœ€å¤§é‡è¯•æ¬¡æ•°: {task_id}")
```

### 3. ä»»åŠ¡å–æ¶ˆ
**åœºæ™¯**ï¼šå®¢æˆ·ç«¯ä¸»åŠ¨å–æ¶ˆä»»åŠ¡

**å¤„ç†**ï¼š
- PENDINGçŠ¶æ€ï¼šç›´æ¥æ ‡è®°ä¸ºCANCELLED
- PROCESSINGçŠ¶æ€ï¼šå–æ¶ˆåç¨‹ï¼Œæ ‡è®°ä¸ºCANCELLED
- å…¶ä»–çŠ¶æ€ï¼šæ— æ³•å–æ¶ˆ

### 4. Workerå¼‚å¸¸
**åœºæ™¯**ï¼šWorkeråç¨‹å†…éƒ¨å¼‚å¸¸

**å¤„ç†**ï¼š
```python
except Exception as e:
    logger.error(f"å·¥ä½œåç¨‹å¼‚å¸¸: {worker_name}, é”™è¯¯: {e}")
    await asyncio.sleep(1)  # ç­‰å¾…1ç§’åç»§ç»­
```

Workerä¼šè‡ªåŠ¨æ¢å¤ï¼Œç»§ç»­å¤„ç†ä¸‹ä¸€ä¸ªä»»åŠ¡ã€‚

## ğŸ” ä½¿ç”¨ç¤ºä¾‹

### Pythonå®¢æˆ·ç«¯ç¤ºä¾‹
```python
import requests
import time
import base64

# 1. æäº¤ä»»åŠ¡
with open("bank_flow.pdf", "rb") as f:
    file_base64 = base64.b64encode(f.read()).decode()

response = requests.post("http://115.190.121.59:8005/analyze", json={
    "file_base64": file_base64,
    "mime_type": "application/pdf",
    "report_type": "flow"
})

task_id = response.json()["task_id"]
print(f"ä»»åŠ¡å·²æäº¤: {task_id}")

# 2. è½®è¯¢ä»»åŠ¡çŠ¶æ€
while True:
    status_response = requests.get(f"http://115.190.121.59:8005/task/{task_id}")
    status_data = status_response.json()

    print(f"ä»»åŠ¡çŠ¶æ€: {status_data['status']}")

    if status_data["status"] in ["completed", "failed", "cancelled"]:
        break

    time.sleep(5)  # æ¯5ç§’æŸ¥è¯¢ä¸€æ¬¡

# 3. è·å–ç»“æœ
if status_data["status"] == "completed":
    result = status_data["result"]
    print("åˆ†æç»“æœ:", result)
else:
    print("ä»»åŠ¡å¤±è´¥:", status_data.get("error_message"))
```

### äº‘å‡½æ•°é›†æˆç¤ºä¾‹
```javascript
// cloudFunctions/processReportAsync/index.js
const cloud = require('wx-server-sdk')
const axios = require('axios')

exports.main = async (event) => {
  const { fileBase64, mimeType, reportType } = event

  // 1. æäº¤ä»»åŠ¡åˆ°AIæœåŠ¡
  const submitResponse = await axios.post(
    'http://115.190.121.59:8005/analyze',
    {
      file_base64: fileBase64,
      mime_type: mimeType,
      report_type: reportType
    }
  )

  const taskId = submitResponse.data.task_id

  // 2. ä¿å­˜ä»»åŠ¡IDåˆ°æ•°æ®åº“
  const db = cloud.database()
  await db.collection('reports').add({
    data: {
      taskId: taskId,
      status: 'pending',
      createdAt: new Date()
    }
  })

  return { success: true, taskId }
}
```

## ğŸ¯ æœ€ä½³å®è·µ

### 1. å®¢æˆ·ç«¯è½®è¯¢ç­–ç•¥
- **è½®è¯¢é—´éš”**ï¼šå»ºè®®5-10ç§’
- **è¶…æ—¶æ—¶é—´**ï¼šå»ºè®®5åˆ†é’Ÿ
- **æŒ‡æ•°é€€é¿**ï¼šå¤±è´¥åé€æ¸å¢åŠ è½®è¯¢é—´éš”

### 2. é˜Ÿåˆ—å®¹é‡è§„åˆ’
- **å¹¶å‘æ•°**ï¼šæ ¹æ®æœåŠ¡å™¨èµ„æºè°ƒæ•´ï¼ˆå½“å‰3ä¸ªï¼‰
- **é˜Ÿåˆ—é•¿åº¦**ï¼šæ ¹æ®ä¸šåŠ¡å³°å€¼è°ƒæ•´ï¼ˆå½“å‰100ä¸ªï¼‰
- **é¢„ä¼°ç­‰å¾…æ—¶é—´**ï¼š`queue_position * 30ç§’`

### 3. é”™è¯¯å¤„ç†å»ºè®®
- **é˜Ÿåˆ—æ»¡**ï¼šæç¤ºç”¨æˆ·ç¨åé‡è¯•
- **ä»»åŠ¡å¤±è´¥**ï¼šæ£€æŸ¥error_messageï¼Œæä¾›å‹å¥½æç¤º
- **è¶…æ—¶**ï¼šå…è®¸ç”¨æˆ·å–æ¶ˆä»»åŠ¡

### 4. ç›‘æ§å‘Šè­¦
- **é˜Ÿåˆ—é•¿åº¦ > 80**ï¼šè€ƒè™‘æ‰©å®¹
- **å¤±è´¥ç‡ > 10%**ï¼šæ£€æŸ¥AIæœåŠ¡çŠ¶æ€
- **å¹³å‡å¤„ç†æ—¶é—´ > 60ç§’**ï¼šä¼˜åŒ–å¤„ç†é€»è¾‘

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–å»ºè®®

### å½“å‰æ€§èƒ½æŒ‡æ ‡
- **æœ€å¤§å¹¶å‘**ï¼š3ä¸ªä»»åŠ¡
- **é˜Ÿåˆ—å®¹é‡**ï¼š100ä¸ªä»»åŠ¡
- **å¹³å‡å¤„ç†æ—¶é—´**ï¼š20-30ç§’/ä»»åŠ¡
- **ååé‡**ï¼šçº¦6-9ä¸ªä»»åŠ¡/åˆ†é’Ÿ

### ä¼˜åŒ–æ–¹å‘
1. **å¢åŠ å¹¶å‘æ•°**ï¼šæå‡åˆ°5-10ä¸ªï¼ˆéœ€è¦æ›´å¤šèµ„æºï¼‰
2. **ä¼˜åŒ–AIè°ƒç”¨**ï¼šç¼“å­˜ã€æ‰¹å¤„ç†
3. **åˆ†å¸ƒå¼é˜Ÿåˆ—**ï¼šä½¿ç”¨Redis/RabbitMQ
4. **ä»»åŠ¡ä¼˜å…ˆçº§**ï¼šVIPç”¨æˆ·ä¼˜å…ˆå¤„ç†
5. **ç»“æœç¼“å­˜**ï¼šç›¸åŒæ–‡ä»¶ç›´æ¥è¿”å›ç¼“å­˜ç»“æœ

## ğŸ”— ç›¸å…³æ–‡ä»¶

- **é˜Ÿåˆ—ç®¡ç†å™¨**ï¼š`ai-analysis-service/app/utils/queue_manager.py`
- **APIè·¯ç”±**ï¼š`ai-analysis-service/app/main.py`
- **æ•°æ®æ¨¡å‹**ï¼š`ai-analysis-service/app/models/report_model.py`
- **AIæœåŠ¡**ï¼š`ai-analysis-service/app/service/ai_service.py`
- **äº‘å‡½æ•°**ï¼š`cloudFunctions/checkTaskStatus/index.js`

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
**æœ€åæ›´æ–°**ï¼š2025-11-26
**ç»´æŠ¤è€…**ï¼šAIåˆ†ææœåŠ¡å›¢é˜Ÿ

